# MODE-SSM: Mode-Aware State-Space Decoder

**Brain-to-Text 2025 Challenge â€“ UC Davis Neuroprosthetics Lab**

## ğŸ§  Overview

MODE-SSM is an end-to-end neural-to-text architecture tailored for decoding intracortical spiking activity (256-channel speech-motor recordings) into text.
It extends the baseline (neuralâ†’phonemeâ†’LM) pipeline  by introducing:

* **State-Space Encoder** for efficient long-sequence modeling.
* **Latent Mode Head** to infer silent vs vocalized speaking strategies .
* **Optional Diffusion/Flow Bridge** for temporal denoising.
* **RNNT + CTC** decoding heads.
* **Corpus-aware LM Fusion** as suggested in the competition overview. 
* **Test-Time Adaptation (TTA)** to handle multi-month neural drift. 

Goal metric: **Word Error Rate (WER)**. 

---

## ğŸ§© Architecture Summary

```
Spikes (256ch, T bins)
   â”‚
   â”œâ”€â”€ Preprocessor (norm + conv stem + channel gating)
   â”‚
   â”œâ”€â”€ SSM Encoder [L=8]  â†â”€ mode-conditioned gains
   â”‚        â”‚
   â”‚        â””â”€â”€ Mode Head p(z|X) âˆˆ {silent,vocalized}
   â”‚
   â”œâ”€â”€ (optional) Denoising Bridge (flow/diffusion)
   â”‚
   â”œâ”€â”€ RNNT Decoder (primary)
   â”œâ”€â”€ CTC Decoder (auxiliary)
   â”‚
   â””â”€â”€ Task-Aware LM Fusion (mode-conditioned)
```

---

## âš™ï¸ Environment

```bash
conda create -n b2t25 python=3.10
conda activate b2t25
pip install torch torchvision torchaudio
pip install hydra-core==1.3.2 datasets sentencepiece
pip install nemo_toolkit[asr]==1.22.0  # RNNT utilities
pip install mamba-ssm==1.2.0 diffusers==0.30.0
pip install pandas h5py jiwer tqdm
```

---

## ğŸ§± Repository Layout

```
.
â”œâ”€â”€ configs/
â”‚   â”œâ”€â”€ train.yaml
â”‚   â”œâ”€â”€ model_mode_ssm.yaml
â”‚   â””â”€â”€ lm_fusion.yaml
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ t15_train.hdf5
â”‚   â”œâ”€â”€ t15_val.hdf5
â”‚   â””â”€â”€ t15_test.hdf5
â”œâ”€â”€ model/
â”‚   â”œâ”€â”€ preprocessor.py
â”‚   â”œâ”€â”€ ssm_encoder.py
â”‚   â”œâ”€â”€ mode_head.py
â”‚   â”œâ”€â”€ denoise_flow.py
â”‚   â”œâ”€â”€ rnnt_ctc_heads.py
â”‚   â”œâ”€â”€ lm_fusion.py
â”‚   â””â”€â”€ tta_loop.py
â”œâ”€â”€ train.py
â”œâ”€â”€ evaluate_model.py
â””â”€â”€ make_submission.py
```

---

## ğŸ§® Training Pipeline

### Stage 1 â€“ Warmup

Train `Preprocessor + SSM Encoder + CTC` only (alignment-free).

```bash
python train.py stage=ctc_warmup
```

### Stage 2 â€“ RNNT + CTC Joint Training

Enable RNNT head and Mode Head; keep CTC auxiliary.

```bash
python train.py stage=joint_train
```

### Stage 3 â€“ Mode Conditioning

Activate soft mode gating (LayerNorm & SSM gains).

```bash
python train.py stage=mode_train
```

### Stage 4 â€“ (Opt.) Denoising Bridge

Turn on diffusion/flow bridge for misalignment smoothing.

```bash
python train.py stage=denoise_train
```

### Stage 5 â€“ Corpus-Aware LM Training

Train small n-gram/neural LMs per corpus type as described by organizers  and export to `lm_fusion.yaml`.

---

## ğŸ”® Test-Time Adaptation (TTA)

Executed automatically at inference:

```bash
python evaluate_model.py --tta true
```

Per-session EMA feature stats â†’ 3â€“10 entropy-minimization steps updating last encoder block only. 

---

## ğŸ§  Inference & Submission

```bash
python make_submission.py \
  --checkpoint checkpoints/mode_ssm/best.pt \
  --config configs/model_mode_ssm.yaml
```

Produces `submission.csv` with:

```
id,text
0,hello there
1,thank you very much
...
```

ordered chronologically (session â†’ block â†’ trial) as required. 

Local evaluation:

```bash
python evaluate_model.py --wer --submission submission.csv --labels val_labels.csv
```

---

## ğŸ§¾ Loss Functions

| Loss        | Purpose                    | Weight |
| ----------- | -------------------------- | ------ |
| `L_RNNT`    | Main sequence loss         | 1.0    |
| `L_CTC`     | Alignment regularizer      | 0.3    |
| `L_mode`    | Latent mode classification | 0.1    |
| `L_denoise` | Flow bridge smoothness     | 0.05   |

---

## ğŸš€ Key Advantages vs Baseline

| Area              | Baseline     | MODE-SSM Improvement                   |
| ----------------- | ------------ | -------------------------------------- |
| Temporal modeling | RNN          | Linear-time SSM captures long context  |
| Mode variance     | Ignored      | Explicit latent mode (z)               |
| Drift adaptation  | None         | Lightweight TTA loop                   |
| Language fusion   | Fixed n-gram | Corpus-specific mode-aware LMs         |
| Robustness        | Static       | Flow denoiser + entropy regularization |

---

## ğŸ“ˆ Expected Leaderboard Impact

* Baseline WER â‰ˆ 6.7 % 
* Target WER â‰ˆ **â‰¤ 5.0 %**
  (gains from mode conditioning + SSM + TTA).

---

## ğŸ§© References

* Card et al., *NEJM* (2024) â€œAn Accurate and Rapidly Calibrating Speech Neuroprosthesis.â€ 
* UC Davis Neuroprosthetics Lab â€“ Brain-to-Text 2025 Overview. 
* Blackrock Neurotech Competition Rules and Submission Format. 
* Mamba: Selective State Space Models (Gu et al., 2024).
* Angrick et al., *Nat Mach Intell* (2021) â€“ Silent speech decoding.
